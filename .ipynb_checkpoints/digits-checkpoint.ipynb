{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nn import (io, nn, preprocess)\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate dataset\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "X_all = digits.data\n",
    "y_all = digits.target\n",
    "# view first digit\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.33, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Autoencoder with 64 x 16 x 64 x 1 layers\n",
    "The two first layers use a ReLU activation function because the digits can be\n",
    "considered as a linear function with outputs ranging from 0 to 9. The final \n",
    "layer is a single node that condenses the output with a sigmoid activation function.\n",
    "This compresses the values to be between 0 and 1.\n",
    "\"\"\"\n",
    "test_arch = [{'input_dim': 64, 'output_dim': 16, 'activation': 'relu'},{'input_dim': 16, 'output_dim': 64, 'activation': 'relu'},{'input_dim': 64, 'output_dim': 1, 'activation': 'sigmoid'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "<br>\n",
    "\tSelection of hyperparamaters:<br>\n",
    "\tI selected the Mean Square Error loss function because the network is using linear<br>\n",
    "\tregression to separate the digits from 0 to 9.<br>\n",
    "\tI selected the other hyperparameters through trial and error until I got ok results.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_auto = nn.NeuralNetwork(nn_arch = test_arch, lr = 0.001, seed = 29, batch_size = 200,epochs = 100, loss_function = \"mse\")\n",
    "# because the last layer of the network is a sigmoid function the outputs are between 0 and 1\n",
    "# so I multiply the y arrays by 0.1 in order to match\n",
    "(train_auto_loss, val_auto_loss) = nn_auto.fit(X_train.T, y_train * 0.1, X_test.T, y_test * 0.1)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.figure()\n",
    "plt.plot(train_auto_loss)\n",
    "plt.title(\"Digit Per Epoch Loss for Training Set\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(val_auto_loss)\n",
    "plt.title(\"Digit Per Epoch Loss for Test Set\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model_prob = nn_auto.predict(X_test.T)\n",
    "model_pred = np.floor(model_prob * 10)\n",
    "print(model_prob[0:10])\n",
    "print(model_pred[0:10])\n",
    "print(y_test[0:10])\n",
    "print('CONFUSION MATRIX')\n",
    "print(confusion_matrix(y_test, model_pred))\n",
    "print('CLASSFICATION REPORT')\n",
    "print(classification_report(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction Error\n",
    "(y_hat,cache) = nn_auto.forward(X_test.T)\n",
    "# the reconstructed images are stored in A2 -- the output of the second layer\n",
    "reconstruction = cache['A2']\n",
    "print(\"RECONSTRUCTION ERROR (MSE)\")\n",
    "reconstruction_error = nn_auto._mean_squared_error(X_test.T, reconstruction)\n",
    "print(reconstruction_error)\n",
    "print(\"PREDICTION ERROR (MSE)\")\n",
    "prediction_error = nn_auto._mean_squared_error(y_test, model_pred)\n",
    "print(prediction_error)\n",
    "print(\"On average, the predicted digit is within \" + str(round(np.sqrt(prediction_error), 2)) + \" of the actual digit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
